<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>&lt;span style&equals;&quot;color&colon;&num;4682B4&semi;&quot; class&equals;&quot;name&quot;&gt;Yueh-Po Peng&lt;&sol;span&gt;</title>
            <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only],
.vscode-high-contrast:not(.vscode-high-contrast-light) img[src$=\#gh-light-mode-only],
.vscode-high-contrast-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
            
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
<style>
:root {
  --color-note: #0969da;
  --color-tip: #1a7f37;
  --color-warning: #9a6700;
  --color-severe: #bc4c00;
  --color-caution: #d1242f;
  --color-important: #8250df;
}

</style>
<style>
@media (prefers-color-scheme: dark) {
  :root {
    --color-note: #2f81f7;
    --color-tip: #3fb950;
    --color-warning: #d29922;
    --color-severe: #db6d28;
    --color-caution: #f85149;
    --color-important: #a371f7;
  }
}

</style>
<style>
.markdown-alert {
  padding: 0.5rem 1rem;
  margin-bottom: 16px;
  color: inherit;
  border-left: .25em solid #888;
}

.markdown-alert>:first-child {
  margin-top: 0
}

.markdown-alert>:last-child {
  margin-bottom: 0
}

.markdown-alert .markdown-alert-title {
  display: flex;
  font-weight: 500;
  align-items: center;
  line-height: 1
}

.markdown-alert .markdown-alert-title .octicon {
  margin-right: 0.5rem;
  display: inline-block;
  overflow: visible !important;
  vertical-align: text-bottom;
  fill: currentColor;
}

.markdown-alert.markdown-alert-note {
  border-left-color: var(--color-note);
}

.markdown-alert.markdown-alert-note .markdown-alert-title {
  color: var(--color-note);
}

.markdown-alert.markdown-alert-important {
  border-left-color: var(--color-important);
}

.markdown-alert.markdown-alert-important .markdown-alert-title {
  color: var(--color-important);
}

.markdown-alert.markdown-alert-warning {
  border-left-color: var(--color-warning);
}

.markdown-alert.markdown-alert-warning .markdown-alert-title {
  color: var(--color-warning);
}

.markdown-alert.markdown-alert-tip {
  border-left-color: var(--color-tip);
}

.markdown-alert.markdown-alert-tip .markdown-alert-title {
  color: var(--color-tip);
}

.markdown-alert.markdown-alert-caution {
  border-left-color: var(--color-caution);
}

.markdown-alert.markdown-alert-caution .markdown-alert-title {
  color: var(--color-caution);
}

</style>
        
        </head>
        <body class="vscode-body vscode-light">
            <h1 id="yueh-po-peng"><span style="color:#4682B4;" class="name">Yueh-Po Peng</span></h1>
<p><a href="mailto:yuehpo.peng@gmail.com"><img src="https://img.shields.io/badge/Email-yuehpo.peng@gmail.com-EA4335?style=flat&amp;logo=gmail&amp;logoColor=white" alt="Email"></a>
<a href="https://github.com/y10ab1"><img src="https://img.shields.io/badge/GitHub-y10ab1-181717?style=flat&amp;logo=github&amp;logoColor=white" alt="GitHub"></a>
<a href="https://www.linkedin.com/in/yueh-po-peng"><img src="https://img.shields.io/badge/LinkedIn-yueh--po--peng-0A66C2?style=flat&amp;logo=linkedin&amp;logoColor=white" alt="LinkedIn"></a>
<a href="https://scholar.google.com/citations?user=uFf4DmoAAAAJ"><img src="https://img.shields.io/badge/Google%20Scholar-Profile-34A853?style=flat&amp;logo=google-scholar&amp;logoColor=white" alt="Google Scholar"></a>
<a href="https://y10ab1.github.io/CV.pdf"><img src="https://img.shields.io/badge/CV-Download-4A90E2?style=flat&amp;logo=adobeacrobatreader&amp;logoColor=white" alt="CV"></a></p>
<h2 id="about-me"><span style="color:#4682B4;">About Me</span></h2>
<p>I am a Research Assistant at the Institute of Information Science, Academia Sinica, focusing on self-supervised learning methods for decoding mental states from brain activity using fMRI data. I have a background in Data Science and Computer Science, with extensive experience in machine learning, neuroscience, and music information research.</p>
<h2 id="experience"><span style="color:#4682B4;">Experience</span></h2>
<ul>
<li>
<p><strong>Institute of Information Science, Academia Sinica, Taipei, Taiwan</strong><br>
Research Assistant (Jul. 2024 – Present)</p>
<ul>
<li>Surveyed end-to-end self-supervised learning methods for decoding mental states from brain activity (fMRI).</li>
<li>Conducted distributed training experiments on large-scale, high-resolution 4D fMRI data using TWCC HPC.</li>
</ul>
</li>
<li>
<p><strong>Tomofun, Taipei, Taiwan</strong><br>
Research &amp; Development - AI Intern (Mar. 2023 – Jul. 2024)</p>
<ul>
<li>Developed an automatic short music video generation system for daily pet clips.</li>
<li>Surveyed various strategies of visual language models (LLaVA) to generate image-caption pairs for knowledge distillation.</li>
</ul>
</li>
<li>
<p><strong>Institute of Information Science, Academia Sinica, Taipei, Taiwan</strong><br>
Research Assistant (Mar. 2022 – Feb. 2023)</p>
<ul>
<li>Proposed a whole-brain feature selection method for decoding musical pitch from brain activity (fMRI).</li>
</ul>
</li>
</ul>
<h2 id="education"><span style="color:#4682B4;">Education</span></h2>
<ul>
<li>
<p><strong>National Taiwan University</strong><br>
M.S. in Data Science (Feb. 2023 – Jun. 2024)</p>
</li>
<li>
<p><strong>National Taiwan University</strong><br>
B.S. in Computer Science and Information Engineering (Sep. 2019 – Jan. 2022)</p>
</li>
</ul>
<h2 id="research--projects"><span style="color:#4682B4;">Research &amp; Projects</span></h2>
<h3 id="guitar-effect-removal">Guitar Effect Removal</h3>
<p><strong>Machine Learning Research on Removing Distortion Effect from Electric Guitar</strong></p>
<ul>
<li>Proposed a two-stage method to remove distortion effects from guitar recordings using Positive Grid VST plugins.</li>
<li>Analyzed baseline models on synthetic and VST-rendered effects, demonstrating superior performance.</li>
<li>Published in DAFx 2024. <a href="https://arxiv.org/abs/2407.16639">Paper</a>, <a href="https://y10ab1.github.io/guitar_effect_removal/">Demo</a></li>
</ul>
<h3 id="whole-brain-fmri-features-selection">Whole Brain fMRI Features Selection</h3>
<p><strong>Machine Learning Research to Find Correlation Between fMRI and Musical Pitch</strong></p>
<ul>
<li>Proposed a two-stage method to extract fMRI features and predict musical pitch.</li>
<li>Evaluated ML models' performance and analyzed correlation between pitch and fMRI patterns.</li>
<li>Published in ICASSP 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10095192">Paper</a></li>
</ul>
<h2 id="publications"><span style="color:#4682B4;">Publications</span></h2>
<ol>
<li>
<p>Ying-Shuo Lee*, <strong>Yueh-Po Peng*</strong>, Jui-Te Wu, Ming Cheng, Li Su, and Yi-Hsuan Yang (2024).<br>
“Distortion recovery: A two-stage method for guitar effect removal.”<br>
In Proc. Int. Conf. Digital Audio Effects (DAFx), 2024. (* equally contributed)</p>
</li>
<li>
<p>Cheung, V. K.*, <strong>Peng, Y. P.*</strong>, Lin, J. H., &amp; Su, L. (2023, June).<br>
“Decoding Musical Pitch from Human Brain Activity with Automatic Voxel-Wise Whole-Brain FMRI Feature Selection.”<br>
In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), (pp. 1-5). IEEE. (* equally contributed)</p>
</li>
</ol>
<h2 id="skills"><span style="color:#4682B4;">Skills</span></h2>
<ul>
<li><strong>Languages/Frameworks</strong>: Python, PyTorch, TensorFlow, Pandas, Scikit-learn, Slurm, Flask, HTML, JavaScript, C++, C, Linux</li>
<li><strong>Skillset</strong>: Machine Learning, Self-Supervised Learning, Neuroscience, Music Information Research, Distributed Training</li>
</ul>

            
            
        </body>
        </html>